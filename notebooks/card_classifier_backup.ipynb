{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "# Set Working Directory\n",
    "os.chdir('/home/ubuntu')\n",
    "\n",
    "# Setup Interactive Environment\n",
    "plt.ion() \n",
    "\n",
    "print(\"Finished environment setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Custom Data Augmentation  Functions\n",
    "\n",
    "def rotate(x):\n",
    "    ''' \n",
    "    Rotate image by 0, 90, 180 or 270 degrees with equal probability.\n",
    "    Preserves Card Invariances.\n",
    "    '''\n",
    "    p = random.uniform(0.0, 1.0)\n",
    "    if p < 0.25:\n",
    "        return x\n",
    "    elif p < 0.5:\n",
    "        return x.rotate(90)\n",
    "    elif p < 0.75:\n",
    "        return x.rotate(180)\n",
    "    else:\n",
    "        return x.rotate(270)\n",
    "    \n",
    "print(\"Data Augmentation Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "'''\n",
    "All pre-trained models expect input images normalized in the same way, \n",
    "i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. \n",
    "The images have to be loaded in to a range of [0, 1] and then normalized using \n",
    "mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n",
    "'''\n",
    "\n",
    "# Data augmentation (by horizontal flipping) and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.Lambda(rotate),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'flattened_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=True, num_workers=16)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(\"Finished Data Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show some images\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "print(\"Finished Showing Images!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "    val_loss = []\n",
    "    epochs =[]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.data[0] * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # prepare plots\n",
    "            if phase == 'train':\n",
    "                train_acc.append(epoch_acc)\n",
    "                train_loss.append(epoch_loss)\n",
    "                epochs.append(epoch-5)\n",
    "            else:\n",
    "                val_acc.append(epoch_acc)\n",
    "                val_loss.append(epoch_loss)\n",
    "                \n",
    "                # Plot Loss After Every Epoch\n",
    "                plt.plot(epochs, train_loss, '-o', epochs, val_loss, '-o')\n",
    "                plt.title('Loss')\n",
    "                plt.show()\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    # Plot Summary\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    # Plot Accuracy at the end of training\n",
    "    plt.plot(epochs, train_acc, '-o', epochs, val_acc, '-o')\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylim(0.5,1.0)\n",
    "    plt.show()\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and fine tune model; Use ResNet18 architecture.\n",
    "\n",
    "model = models.resnet34(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 52)\n",
    "print(\"Initialized Model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze Early Layers for fine-tuning\n",
    "    \n",
    "child_counter = 0\n",
    "for child in model.children():\n",
    "    if child_counter < 7:\n",
    "        print(\"child \",child_counter,\" was frozen\")\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif child_counter == 6:\n",
    "        children_of_child_counter = 0\n",
    "        for children_of_child in child.children():\n",
    "            if children_of_child_counter < 1:\n",
    "                for param in children_of_child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                print('child ', children_of_child_counter, 'of child',child_counter,' was frozen')\n",
    "            else:\n",
    "                print('child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
    "            children_of_child_counter += 1\n",
    "\n",
    "    else:\n",
    "        print(\"child \",child_counter,\" was not frozen\")\n",
    "    child_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    print(\"Enabled GPU.\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Initialized Loss.\")\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01, momentum=0.9)\n",
    "print(\"Initialized Optimizer.\")\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "print(\"Initialized Hyperparameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=30)\n",
    "\n",
    "print(\"Finished training bitch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze Net for Feature Extraction (all but final layer)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# model.fc.requires_grad = True\n",
    "\n",
    "model_opt = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t_imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "    \n",
    "def visualize_model(model, num_images=16):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        img_per_col = 4\n",
    "        gs = gridspec.GridSpec(num_images//img_per_col, img_per_col)\n",
    "        for j in range(inputs.size()[0]):\n",
    "            ax = plt.subplot(gs[images_so_far // img_per_col, images_so_far % img_per_col])\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "            t = t_imshow(inputs.cpu().data[j])\n",
    "            ax.imshow(t)\n",
    "            \n",
    "            images_so_far += 1\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                model.train(mode=was_training)\n",
    "                return\n",
    "    model.train(mode=was_training)\n",
    "\n",
    "    \n",
    "visualize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Validation Accuracy for each Class\n",
    "\n",
    "def compute_class_acc(model):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    class_acc = np.zeros(52)\n",
    "    class_count = np.zeros(52)\n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            # update per class errors\n",
    "            class_count[labels.data[j]] = class_count[labels.data[j]] + 1.0\n",
    "            class_acc[labels.data[j]] = class_acc[labels.data[j]] + (labels.data[j] == preds[j])\n",
    "    \n",
    "    return (class_acc / class_count), class_count, (sum(class_acc) / sum(class_count))\n",
    "\n",
    "accuracies, class_count, total_acc = compute_class_acc(model)\n",
    "print(\"Validation Accuracy:\", total_acc)\n",
    "for (name, acc, count) in zip(class_names, accuracies, class_count):\n",
    "    print(name, \" - \", acc * 100, \"%\", \" - \", count, \"instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
